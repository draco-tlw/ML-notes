## **Polynomial Regression: Fitting Curves ðŸŽ¢**

**Polynomial regression** is a powerful technique that combines multiple linear regression with **feature engineering** to fit complex, **non-linear curves** to the data. It's used when a simple straight line is not a good fit for the underlying relationship between the features and the target.

---

### **Creating Polynomial Features**

The core idea is to create new features by raising an original feature to different powers.

- **Example:** For a single feature `x` (like house size), you can create new features to build more complex models:
  - **Quadratic Model:** Use $x$ and $x^2$. The model becomes $f(x) = w_1x + w_2x^2 + b$. This can fit a parabolic curve.
  - **Cubic Model:** Use $x$, $x^2$, and $x^3$. The model becomes $f(x) = w_1x + w_2x^2 + w_3x^3 + b$. This can fit a more complex S-shaped curve.

---

### **The Importance of Feature Scaling**

When you use polynomial regression, **feature scaling becomes extremely important**.

- **Reason:** The ranges of the engineered features can become drastically different.
  - If `x` (size) ranges from 1 to 1,000...
  - Then $x^2$ (size squared) ranges from 1 to 1,000,000.
  - And $x^3$ (size cubed) ranges from 1 to 1,000,000,000.
- **Impact:** Without scaling, these vastly different ranges will cause gradient descent to converge very slowly and inefficiently.

---

### **Other Feature Choices**

You are not limited to just polynomial terms. You can engineer other non-linear features based on your understanding of the data.

- **Example:** You could use the **square root** of a feature.
  - **Model:** $f(x) = w_1x + w_2\sqrt{x} + b$
  - The square root function increases but at a decreasing rate, which might be a suitable model for some datasets.

**How to Choose Features:** Deciding which features to create or use is a key part of building a good model. Later in the specialization, you will learn systematic ways to evaluate and select the best features for your problem.
